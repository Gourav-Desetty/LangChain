{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81567276",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "\n",
    "LangChain document \n",
    "* page content(str)\n",
    "* metadata (dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b34012",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71992c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(\n",
    "    page_content=\"this is the main content im using in rag paper\",\n",
    "    metadata ={\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\":1,\n",
    "        \"author\": \"Robert Frost\",\n",
    "        \"data-created\": \"2025-09-16\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08bccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc4543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = {\n",
    "\"../data/text_files/content.txt\":\"\"\" Socompa is a large stratovolcano (composite volcano) on the border of Argentina and Chile.\n",
    "    It has an elevation of 6,051 metres (19,852 ft) and is part of the Chilean and Argentine Andean Volcanic Belt (AVB). \n",
    "    Socompa is within the Central Volcanic Zone, one of the segments of the AVB, which contains about 44 active volcanoes. \n",
    "    It begins in Peru and runs first through Bolivia and Chile, and then Argentina and Chile. \n",
    "    Socompa lies close to the pass of the same name where the Salta-Antofagasta railway crosses the Chilean border.\n",
    "\n",
    "    Most of the northwestern slope of Socompa collapsed catastrophically 7,200 years ago to form an extensive debris avalanche deposit. \n",
    "    The Socompa collapse is among the largest known on land with a volume of 19.2 cubic kilometres (4.6 cu mi) and a surface area of 490 square \n",
    "    kilometres (190 sq mi); its features are well-preserved by the arid climate. The deposit was at first considered to be either a moraine or a \n",
    "    pyroclastic flow deposit, until the 1980 eruption of Mount St. Helens prompted awareness of the instability of volcanic edifices and the \n",
    "    existence of large-scale collapses. There are large toreva blocks, which were left behind within the collapse crater. \n",
    "    After the landslide, the volcano was rebuilt by the effusion of lava flows and much of the scar is now filled in.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c834b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, content in sample_text.items():\n",
    "    with open(path, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883d164c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/content.txt'}, page_content=' Socompa is a large stratovolcano (composite volcano) on the border of Argentina and Chile.\\n    It has an elevation of 6,051 metres (19,852 ft) and is part of the Chilean and Argentine Andean Volcanic Belt (AVB). \\n    Socompa is within the Central Volcanic Zone, one of the segments of the AVB, which contains about 44 active volcanoes. \\n    It begins in Peru and runs first through Bolivia and Chile, and then Argentina and Chile. \\n    Socompa lies close to the pass of the same name where the Salta-Antofagasta railway crosses the Chilean border.\\n\\n    Most of the northwestern slope of Socompa collapsed catastrophically 7,200 years ago to form an extensive debris avalanche deposit. \\n    The Socompa collapse is among the largest known on land with a volume of 19.2 cubic kilometres (4.6 cu mi) and a surface area of 490 square \\n    kilometres (190 sq mi); its features are well-preserved by the arid climate. The deposit was at first considered to be either a moraine or a \\n    pyroclastic flow deposit, until the 1980 eruption of Mount St. Helens prompted awareness of the instability of volcanic edifices and the \\n    existence of large-scale collapses. There are large toreva blocks, which were left behind within the collapse crater. \\n    After the landslide, the volcano was rebuilt by the effusion of lava flows and much of the scar is now filled in.\\n')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/content.txt\", encoding='utf-8')\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9542904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\content.txt'}, page_content=' Socompa is a large stratovolcano (composite volcano) on the border of Argentina and Chile.\\n    It has an elevation of 6,051 metres (19,852 ft) and is part of the Chilean and Argentine Andean Volcanic Belt (AVB). \\n    Socompa is within the Central Volcanic Zone, one of the segments of the AVB, which contains about 44 active volcanoes. \\n    It begins in Peru and runs first through Bolivia and Chile, and then Argentina and Chile. \\n    Socompa lies close to the pass of the same name where the Salta-Antofagasta railway crosses the Chilean border.\\n\\n    Most of the northwestern slope of Socompa collapsed catastrophically 7,200 years ago to form an extensive debris avalanche deposit. \\n    The Socompa collapse is among the largest known on land with a volume of 19.2 cubic kilometres (4.6 cu mi) and a surface area of 490 square \\n    kilometres (190 sq mi); its features are well-preserved by the arid climate. The deposit was at first considered to be either a moraine or a \\n    pyroclastic flow deposit, until the 1980 eruption of Mount St. Helens prompted awareness of the instability of volcanic edifices and the \\n    existence of large-scale collapses. There are large toreva blocks, which were left behind within the collapse crater. \\n    After the landslide, the volcano was rebuilt by the effusion of lava flows and much of the scar is now filled in.\\n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Directory loader\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob = \"**/*.txt\",\n",
    "    loader_cls = TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd16c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AgenticAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, PyPDFLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls= PyMuPDFLoader,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "all_pdf_documents = dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370a30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7110d9a",
   "metadata": {},
   "source": [
    "## Embedding and Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306718c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb17b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"Split documents into smaller chunks for better RAG performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    # Show example chunk\n",
    "    if split_docs:\n",
    "        print(\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9f75d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 11 documents into 43 chunks\n",
      "\n",
      "Example chunk:\n",
      "Content: Attention Is All You Need\n",
      "Ashish Vaswani∗\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer∗\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar∗\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit∗\n",
      "Google Research\n",
      "usz...\n",
      "Metadata: {'producer': 'PyPDF2', 'creator': '', 'creationdate': '', 'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf', 'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'format': 'PDF 1.3', 'title': 'Attention is All you Need', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'keywords': '', 'moddate': '2018-02-12T21:22:10-08:00', 'trapped': '', 'modDate': \"D:20180212212210-08'00'\", 'creationDate': '', 'page': 0}\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(all_pdf_documents)\n",
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "708cca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadding Embedding Model: all-MiniLM-L6-v2\n",
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loadding Embedding Model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise \n",
    "\n",
    "    def generate_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        print(f\"Generate embeddings for {len(texts)} texts...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generate embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Initialise the embedding manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3751e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1cd667d30b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce7cc5",
   "metadata": {},
   "source": [
    "## Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2614b6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectore store initialized. Collection: pdf_documents\n",
      "Existent document in collection: 43\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = \"pdf_documents\", persist_directory:str = \"../data/vector_store\") :\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self.initialize_store()\n",
    "\n",
    "    def initialize_store(self):\n",
    "        try:\n",
    "            # Create a persist chroma db client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True) \n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            # Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embedding for rag\"}\n",
    "            )\n",
    "            print(f\"Vectore store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existent document in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "\n",
    "        print(f\"Adding: {len(documents)} documents to vector store\")\n",
    "\n",
    "        # Prepare data for chromedb\n",
    "        ids = []\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # Generate unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #Prepare the metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            # Document Content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            # Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids = ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text\n",
    "            )\n",
    "            print(f\"Successfully added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding documents to vector store: {e}\")\n",
    "\n",
    "\n",
    "vector_store = VectorStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4f51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1cd67c09940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d319529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings for 43 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (43, 384)\n",
      "Adding: 43 documents to vector store\n",
      "Successfully added 43 documents to vector store\n",
      "Total documents in collection: 86\n",
      "Collection count: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Convert the text to embeddings\n",
    "text = [doc.page_content for doc in chunks]\n",
    "\n",
    "\n",
    "# Generate the embeddings \n",
    "embeddings = embedding_manager.generate_embeddings(texts=text)\n",
    "\n",
    "# store in the vector database\n",
    "vector_store.add_documents(documents=chunks, embeddings=embeddings)\n",
    "print(\"Collection count:\", vector_store.collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdf813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08a2d85b",
   "metadata": {},
   "source": [
    "## Retriever pipeline from Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71d38bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetriever:\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager) :\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self, query: str, top_k:int = 5, score_threshold:float = -1) -> List[Dict[str, Any]]:\n",
    "        print(f\"Retrieving documents for query: {query}\")\n",
    "        print(f\"Top k: {top_k}, Score Threshold: {score_threshold}\")\n",
    "\n",
    "        # Generate query embedding\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        # Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings = [query_embedding.tolist()],\n",
    "                n_results = top_k\n",
    "            )\n",
    "\n",
    "            #Process Results\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in  enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # convert distance to similarity score(chromadb uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} documents (after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        except Exception as e:\n",
    "            print(\"Error during query:\", e)\n",
    "            return []\n",
    "\n",
    "\n",
    "\n",
    "rag_retriever = RAGRetriever(vector_store=vector_store, embedding_manager=embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f780a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: what is attention is all you need?\n",
      "Top k: 5, Score Threshold: -1\n",
      "Generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 141.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 5 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_c6fe3612_25',\n",
       "  'content': 'convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece',\n",
       "  'metadata': {'format': 'PDF 1.3',\n",
       "   'keywords': '',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'modDate': \"D:20180212212210-08'00'\",\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'content_length': 969,\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'doc_index': 25,\n",
       "   'creationDate': '',\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'page': 6,\n",
       "   'title': 'Attention is All you Need',\n",
       "   'creator': '',\n",
       "   'producer': 'PyPDF2',\n",
       "   'trapped': '',\n",
       "   'creationdate': '',\n",
       "   'total_pages': 11},\n",
       "  'similarity_score': -0.10704755783081055,\n",
       "  'distance': 1.1070475578308105,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_3185a7e5_25',\n",
       "  'content': 'convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece',\n",
       "  'metadata': {'producer': 'PyPDF2',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'total_pages': 11,\n",
       "   'format': 'PDF 1.3',\n",
       "   'keywords': '',\n",
       "   'creationdate': '',\n",
       "   'page': 6,\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'modDate': \"D:20180212212210-08'00'\",\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'creationDate': '',\n",
       "   'creator': '',\n",
       "   'content_length': 969,\n",
       "   'trapped': '',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'doc_index': 25},\n",
       "  'similarity_score': -0.10704755783081055,\n",
       "  'distance': 1.1070475578308105,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_a662a754_21',\n",
       "  'content': 'during training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to',\n",
       "  'metadata': {'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'trapped': '',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'creator': '',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'total_pages': 11,\n",
       "   'creationDate': '',\n",
       "   'doc_index': 21,\n",
       "   'page': 5,\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'modDate': \"D:20180212212210-08'00'\",\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'producer': 'PyPDF2',\n",
       "   'creationdate': '',\n",
       "   'keywords': '',\n",
       "   'format': 'PDF 1.3',\n",
       "   'content_length': 936},\n",
       "  'similarity_score': -0.1371856927871704,\n",
       "  'distance': 1.1371856927871704,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_54434581_21',\n",
       "  'content': 'during training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to',\n",
       "  'metadata': {'doc_index': 21,\n",
       "   'content_length': 936,\n",
       "   'creator': '',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'keywords': '',\n",
       "   'creationdate': '',\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'page': 5,\n",
       "   'format': 'PDF 1.3',\n",
       "   'producer': 'PyPDF2',\n",
       "   'creationDate': '',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'total_pages': 11,\n",
       "   'modDate': \"D:20180212212210-08'00'\",\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'trapped': '',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00'},\n",
       "  'similarity_score': -0.1371856927871704,\n",
       "  'distance': 1.1371856927871704,\n",
       "  'rank': 4},\n",
       " {'id': 'doc_dbf3385a_7',\n",
       "  'content': 'described in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 22, 23, 19].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate',\n",
       "  'metadata': {'doc_index': 7,\n",
       "   'total_pages': 11,\n",
       "   'creationDate': '',\n",
       "   'creationdate': '',\n",
       "   'trapped': '',\n",
       "   'modDate': \"D:20180212212210-08'00'\",\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'source': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'keywords': '',\n",
       "   'creator': '',\n",
       "   'content_length': 934,\n",
       "   'producer': 'PyPDF2',\n",
       "   'format': 'PDF 1.3',\n",
       "   'file_path': '..\\\\data\\\\pdf\\\\attention-is-all-you-need-Paper.pdf',\n",
       "   'page': 1},\n",
       "  'similarity_score': -0.16129207611083984,\n",
       "  'distance': 1.1612920761108398,\n",
       "  'rank': 5}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retriever.retrieve(\"what is attention is all you need?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb38c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa68b47a",
   "metadata": {},
   "source": [
    "## Integrate vectordb context pipeline with llm output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3389f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple rag pipeline with groq llm\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "## initialize the groq llm\n",
    "groq_api_key1 = os.getenv(\"GROQ_API_KEY1\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key = groq_api_key1, model=\"gemma2-9b-it\", temperature=0.1, max_tokens=1024)\n",
    "\n",
    "##simple rag function: retrieve context + generate response\n",
    "def rag_simple(query, retriever, llm, top_k = 3):\n",
    "    ## retrieve the context\n",
    "    results = retriever.retrieve(query, top_k = top_k)\n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in results]) if results else \"\"\n",
    "    if not context:\n",
    "        return \"No relevant context found\"\n",
    "    \n",
    "    # generate the answer with llm\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt.format(context=context, query=query))\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4825ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: what is attention is all you need?\n",
      "Top k: 3, Score Threshold: -1\n",
      "Generate embeddings for 1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 133.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate embeddings with shape: (1, 384)\n",
      "Retrieved 3 documents (after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Attention Is All You Need\" is a paper that proposes a novel network architecture called the Transformer, which relies entirely on self-attention mechanisms to process sequential data.  \n",
      "\n",
      "The paper argues that self-attention is a more effective and efficient alternative to traditional recurrent and convolutional networks for tasks like machine translation. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"what is attention is all you need?\", rag_retriever, llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8743a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1351d5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03afbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6d223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33bb39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
