{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b172633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c499c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def division(a: int, b: int) -> float:\n",
    "    \"\"\"Divide two numbers and return the result.\"\"\"\n",
    "    return a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a007d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division\n",
      "Divide two numbers and return the result.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(division.name)\n",
    "print(division.description)\n",
    "print(division.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ba5e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "async def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a*b\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc304fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[int, \"A Value\"],\n",
    "    b: Annotated[List[int], \"list of ints over which  to take maximum\"]\n",
    ") -> int:\n",
    "    \"\"\"multiply A by the maximum B\"\"\"\n",
    "    return a * max(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'description': 'A Value', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'list of ints over which  to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2496e0e3",
   "metadata": {},
   "source": [
    "### Structured tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5cde8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "def multiply (a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "async def amultiply (a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\":2, \"b\":3}))\n",
    "print(await calculator.ainvoke({\"a\":2, \"b\":5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61da75",
   "metadata": {},
   "source": [
    "## Inbuilt tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc40d1",
   "metadata": {},
   "source": [
    "### wikipedia integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc97309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=5, doc_content_chars_max=500)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83154039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70acb9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTAVILY_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mTAVILY_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:719\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:779\u001b[39m, in \u001b[36mcheck_str\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"T_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f16fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool2 = TavilySearch(\n",
    "    max_results = 5,\n",
    "    topic = \"general\",\n",
    "    tavily_api_key = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7bb702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is the recent ai news?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.crescendo.ai/news/latest-ai-news-and-updates',\n",
       "   'title': 'The Latest AI News and AI Breakthroughs that Matter Most: 2025',\n",
       "   'content': 'Summary: DeepCogito v2, an open-source AI model, has been released with improved logical reasoning and task planning. Developers say it outperforms many closed',\n",
       "   'score': 0.73778254,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.artificialintelligence-news.com/',\n",
       "   'title': 'AI News | Latest AI News, Analysis & Events',\n",
       "   'content': \"SoftBank chief: Forget AGI, ASI will be here within 10 years · Malaysia launches Ryt Bank, its first AI-powered bank · Google's Veo 3 AI video creation tools\",\n",
       "   'score': 0.67243975,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.wsj.com/tech/ai?gaa_at=eafs&gaa_n=ASWzDAiTdRo2rvZlEirbw0jENeqPUB-9nRiROBV5vOYQV1bkIGt5AUzMdnsl&gaa_ts=68c79f3f&gaa_sig=St2UH-9cUcJlHuYLi-D8di6-vpsIS68jh3gsUxG-B6p_QNzEjsKqk8vc1YEvBfals-poyXRw3uFHoeLLg1I4Eg%3D%3D',\n",
       "   'title': 'Artificial Intelligence - Latest AI News and Analysis - WSJ.com',\n",
       "   'content': 'Oracle, OpenAI Sign $300 Billion Cloud Deal · The deal is one of the largest cloud contracts ever signed, reflecting how spending on AI data centers is hitting',\n",
       "   'score': 0.65173227,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.nbcnews.com/artificial-intelligence',\n",
       "   'title': 'Artificial intelligence - NBC News',\n",
       "   'content': \"The latest news and top stories on artificial intelligence, including AI chatbots like Microsoft's ChatGPT, Apple's AI Chatbot and Google's Bard.\",\n",
       "   'score': 0.6415577,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://blog.google/technology/ai/google-ai-updates-august-2025/',\n",
       "   'title': 'The latest AI news we announced in August - Google Blog',\n",
       "   'content': 'Google made many AI advancements in August. You can now use AI Mode in Search in more countries and Deep Think in the Gemini app. Google also',\n",
       "   'score': 0.6155738,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.05,\n",
       " 'request_id': '9fafed39-67b4-4a41-a6fa-8b793dc4fda9'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool2.invoke(\"what is the recent ai news?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a28bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2025-09-04\\nTitle: Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model\\nAuthors: Phuoc-Nguyen Bui, Khanh-Binh Nguyen, Hyunseung Choo\\nSummary: Contrastive vision-language models excel in zero-shot image recognition but\\nface challenges in few-shot scenarios due to computationally intensive offline\\nfine-tuning using prompt learning, which risks overfitting. To overcome these\\nlimitations, we propose Attn-Adapter, a novel online few-shot learning\\nframework that enhances CLIP's adaptability via a dual attention mechanism. Our\\ndesign incorporates dataset-specific information through two components: the\\nMemory Attn-Adapter, which refines category embeddings using support examples,\\nand the Local-Global Attn-Adapter, which enriches image embeddings by\\nintegrating local and global features. This architecture enables dynamic\\nadaptation from a few labeled samples without retraining the base model.\\nAttn-Adapter outperforms state-of-the-art methods in cross-category and\\ncross-dataset generalization, maintaining efficient inference and scaling\\nacross CLIP backbones.\""
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "tool = ArxivAPIWrapper()\n",
    "\n",
    "tool.run(\"2509.03895\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ac077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c57027c",
   "metadata": {},
   "source": [
    "## Call tool with llm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of \n"
     ]
    }
   ],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "tool1 = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool1.invoke({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a:int, b:int) -> int:\n",
    "    \"\"\"ADD two numbers\"\"\"\n",
    "    return a+b\n",
    "\n",
    "@tool\n",
    "def mul(a:int, b:int)-> int:\n",
    "    \"\"\"Multipy two numbers\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool1, tool2, add, mul]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc82978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001AA665FCEF0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001AA66D4C920>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"qwen/qwen3-32b\", model_provider=\"groq\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f995ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001AA665FCEF0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001AA66D4C920>, model_name='qwen/qwen3-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': \"Determines whether to include favicon URLs for each search result.\\n        \\n        When enabled, each search result will include the website's favicon URL,\\n        which can be useful for:\\n        - Building rich UI interfaces with visual website indicators\\n        - Providing visual cues about the source's credibility or brand\\n        - Creating bookmark-like displays with recognizable site icons\\n        \\n        Set to True when creating user interfaces that benefit from visual branding\\n        or when favicon information enhances the user experience.\\n        \\n        Default is False to minimize response size and API usage.\\n        \"}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'add', 'description': 'ADD two numbers', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'mul', 'description': 'Multipy two numbers', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tools = llm.bind_tools(tools)\n",
    "llm_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'reasoning_content': 'Okay, let\\'s see. The user is asking \"what is 2*3\". That\\'s a multiplication problem. I need to figure out which tool to use here. Looking at the available functions, there\\'s one called \"mul\" which is for multiplying two numbers. The parameters required are \"a\" and \"b\", both integers. So, in this case, a is 2 and b is 3. I should call the mul function with these values. No other functions seem relevant here, like wikipedia or tavily_search, since it\\'s a straightforward math problem. The answer should be 6. Let me make sure the parameters are correct and then format the tool call accordingly.\\n', 'tool_calls': [{'id': 'a0svnfe5j', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'mul'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 169, 'prompt_tokens': 2055, 'total_tokens': 2224, 'completion_time': 0.32116248, 'prompt_time': 0.1158091, 'queue_time': 0.069258819, 'total_time': 0.43697158}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--0f83914a-1eef-4cd4-9f1f-c6e8e348e229-0' tool_calls=[{'name': 'mul', 'args': {'a': 2, 'b': 3}, 'id': 'a0svnfe5j', 'type': 'tool_call'}] usage_metadata={'input_tokens': 2055, 'output_tokens': 169, 'total_tokens': 2224}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "query = \"what is 2*3\"\n",
    "messages = [HumanMessage(query)]\n",
    "response = llm_tools.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f110cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'mul',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'a0svnfe5j',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf946f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is 2*3', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='6', name='mul', tool_call_id='a0svnfe5j')]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"mul\": mul, \"wikipedia\": tool1, \"tavily_search\": tool2}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6c0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of multiplying 2 by 3 is 6.\\n\\n$$\\n2 \\\\times 3 = 6\\n$$', additional_kwargs={'reasoning_content': 'Okay, the user asked \"what is 2*3\". I need to multiply 2 and 3. There\\'s a function called mul for multiplication. Let me check the parameters: it requires a and b as integers. So I\\'ll call mul with a=2 and b=3. The response should be 6.\\n'}, response_metadata={'token_usage': {'completion_tokens': 97, 'prompt_tokens': 2065, 'total_tokens': 2162, 'completion_time': 0.175020913, 'prompt_time': 0.154724112, 'queue_time': 0.064028117, 'total_time': 0.329745025}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c6297147-87d3-4e79-a971-3c911889dee8-0', usage_metadata={'input_tokens': 2065, 'output_tokens': 97, 'total_tokens': 2162})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b19e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287be993",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is langchain and what is 5*3?\"\n",
    "mess = [HumanMessage(query)]\n",
    "ai_mess = llm_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a94024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'LangChain'},\n",
       "  'id': 'z8xvjmrmq',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'mul',\n",
       "  'args': {'a': 5, 'b': 3},\n",
       "  'id': 'gwprems5z',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_mess.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e5313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what is langchain and what is 5*3?', additional_kwargs={}, response_metadata={}),\n",
       " ToolMessage(content='Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of ', name='wikipedia', tool_call_id='z8xvjmrmq'),\n",
       " ToolMessage(content='15', name='mul', tool_call_id='gwprems5z')]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_mess.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"mul\": mul, \"wikipedia\": tool1, \"tavily_search\": tool2}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    mess.append(tool_msg)\n",
    "\n",
    "mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7708ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_tools.invoke(mess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a software framework designed to simplify the integration of large language models (LLMs) into applications. It provides tools for managing prompts, handling data, and orchestrating workflows, enabling developers to build AI-powered applications more efficiently.\\n\\nFor the mathematical question:  \\n5 multiplied by 3 equals **15**.'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e00999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fbcc36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
